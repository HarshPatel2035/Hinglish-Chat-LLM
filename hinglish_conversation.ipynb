{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15636,
     "status": "ok",
     "timestamp": 1764941233228,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "eaJ0gZ7nLDtm",
    "outputId": "f2d973df-7269-48d8-fec7-60398fd2df99"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"transformers>=4.42.0\" \"datasets>=2.20.0\" \"peft>=0.12.0\" \"accelerate>=0.30.0\" einops\n",
    "\n",
    "import torch\n",
    "print(\"Using device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37142,
     "status": "ok",
     "timestamp": 1764941270378,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "uW8eD8ruMWXB",
    "outputId": "cb0e791c-852c-48f3-ba09-932e27044f26"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312,
     "referenced_widgets": [
      "c420dba77e674a25ace164b627e1710d",
      "32a7ebcc58ed4c628339c048c97b1b14",
      "066603d6dd084cdf99e9f665111dac66",
      "31d8e294a6ec4515a574ba4cb59af503",
      "09e6d8bb430e4800acd24c93bbae4dd7",
      "c4b7ccb3cf394560b6dfd6b1f79cec28",
      "9e839f246fad4d91923c3552c86240e6",
      "353107b6f8ca4f0a8d5d4d29081e0d47",
      "a1736060a5a54a7989a5acc7587ae161",
      "031dfce03b7e4a65a752f426a85fc301",
      "295746ae996b48049ccc490cc42dff77",
      "55bf745865c4445ea3dcbbbc46e42794",
      "fbabbd9b889a4b3d967433113014bc99",
      "35b41125e77b4c07b252a691a30aac2d",
      "9559498686c848a28341aec0d0698385",
      "2aec600422aa4949899df0aad150a27a",
      "f8e1f1dc58a84421ace521018bdc1b85",
      "edae2da8d7a64ec7be56eb819887721c",
      "487881422c7d4330a14a6ddb1f6ee222",
      "bcdd1b6abec94cf696c2d5785609eb76",
      "b628b3e0ee254e4f8df33fce137c00f7",
      "2ddded16fd3d40ac907619049955b1b3",
      "683a1b53ce9f456d976ac74c67f5c0f3",
      "68808ddbb7284be1b17f7ffdf1baa833",
      "4629ac5ebeab4fc3aa1e51a73515bb5f",
      "963be35d532e430a8d60a8bc5acd370d",
      "4e2bc5a3e01c4db883a926aaf09b0037",
      "efd0c34d081c40a0bfe489974daaa1b2",
      "40ac1df6ee35467a9ef6342c32ac183d",
      "b9b5561ee3534e679d916921363b204a",
      "55d0235d7162429390a31ca79ff0c319",
      "b8cfd62f5345497eb6701e4fec553046",
      "9650c94c755943678ce71b658d5991a7"
     ]
    },
    "executionInfo": {
     "elapsed": 12953,
     "status": "ok",
     "timestamp": 1764941283329,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "lBTrrbBXMa1A",
    "outputId": "49b6565d-eea9-4a42-8cf4-ff937dfddbf2"
   },
   "outputs": [],
   "source": [
    "# Load full train split\n",
    "dataset = load_dataset(\"Abhishekcr448/Hinglish-Everyday-Conversations-1M\", split=\"train\")\n",
    "print(\"Total rows in original dataset:\", len(dataset))\n",
    "print(dataset[0])\n",
    "\n",
    "# OPTIONAL: use a subset to keep training manageable\n",
    "max_samples = 50000   # change if you want more/less\n",
    "if len(dataset) > max_samples:\n",
    "    dataset = dataset.shuffle(seed=42).select(range(max_samples))\n",
    "\n",
    "print(\"Rows used for training:\", len(dataset))\n",
    "print(dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "8e43083fc38b4c70b5ed2cf1c7fc6bf7",
      "c3706aa46ab646edbd7ace361d8f294e",
      "c1e2b57d69e945cbbba20cfb3e673d27",
      "b48a2a2a0c964869afbf8af9f4a2e66d",
      "de2990e709b1472782f6624da1919a89",
      "72903387d50a4b1ab2b2737a8b8e8fde",
      "530af53394cf4b6b9003cf3d906828ce",
      "539a1b70c508408e9069fe2eb982ba13",
      "6baeb3731c5241e1be3968a7cb930c96",
      "0c176658899d476daf5821605a8c9fc8",
      "95eeaa2d86b84bd6a7074aabdff0e6a7"
     ]
    },
    "executionInfo": {
     "elapsed": 14494,
     "status": "ok",
     "timestamp": 1764941297826,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "0Ce8BdoqMcnj",
    "outputId": "84ad1d9c-5b18-401f-bd18-0a0f7723c8c1"
   },
   "outputs": [],
   "source": [
    "def format_example(example):\n",
    "    user = example[\"input\"].strip()\n",
    "    bot = example[\"output\"].strip()\n",
    "    # Simple conversation format; you can later change persona while generating\n",
    "    text = f\"<user>: {user}\\n<assistant>: {bot}\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "formatted_ds = dataset.map(format_example, remove_columns=dataset.column_names)\n",
    "print(formatted_ds[0])\n",
    "\n",
    "# Train / eval split\n",
    "splits = formatted_ds.train_test_split(test_size=0.01, seed=42)\n",
    "train_raw = splits[\"train\"]\n",
    "eval_raw = splits[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_raw), \"Eval size:\", len(eval_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "5069424a25ff4db6bfcbb1d532468aa3",
      "e6f4ef4e3aa047e69a048a5d132855a9",
      "841f0be6b9d94be09d6744834428bfba",
      "af1c72baf1004876b50b43b9c6f9f461",
      "9e1d41ec89d947599b3ce59c5f2d2b5f",
      "883afcc4f5774baabf48b715edca0431",
      "81db59ba7a2f48bd96f5254ef785e63a",
      "2087c82b7fbe452791274cf777f99211",
      "04c82627a2c1489db27b3bd981df5bf6",
      "fc8f0373633d4796b040cfcd81ae1a56",
      "9406bb10d43f49c695cbf35d6b05dd28",
      "7e674bf8d5c649b9bbe825037106fe59",
      "65d24a89d5b541f9b6875c5c60864ab3",
      "4854650bcbfc496985ff45a47458ffb5",
      "28d6b4e0a01344b6a808de49808b0794",
      "9025483acd7342d0be0c2577a1f8aa3d",
      "ef879ee42efd49bbb6eae2a8058b74c0",
      "5d851c8c741d4cc4b0ed22dc24f6c6a9",
      "61bdbe6e1bcd4c11984d7f10bd33048d",
      "af35a3d639a34d94a430243d18cf5956",
      "843603f6e8cc47edb16f2966749a59ce",
      "90458cce55ad4dbc8a97c0c4871f492e",
      "84ba42664a0a40ad89965da918b0b701",
      "bf3a66d20dbe4380b174ab1869df30a4",
      "ff9d6509b4304617b62972c441b830e1",
      "b870b6bf93174c3f9e5ef0f9ea651850",
      "5f6e58188dc64431aae32848ace821d4",
      "54b0cc6da49e41569b2a3a0664cd6b7b",
      "68853c93b04a4a8da43fca8fb9397c87",
      "cdf7686102664072b9f1bc92596b3b26",
      "0ad4090d16e84f36a00b0b74c8a2fd71",
      "05f9fe84111c4a19925b3acabc8a3a09",
      "4ec92c67f9a4431baab451154bf61c1c",
      "519e133732f3474e87f1783816bb0d6f",
      "fa165c88dfab44688578037970f1f480",
      "852632c1f8db488bac7ee1fa26fb0e42",
      "6c36952837134f138d006ee76ee22cf8",
      "a4763884bcf241d89c37040e17d13a32",
      "f6bb23e49a384d969581fad1a07799d2",
      "02d4a79e4730469db9a4cfb9228a1e00",
      "51e4989fdb3f40578a63241058befd22",
      "a11f30f9547d49ea8fee844d53562bcc",
      "7c1cee550c12410aa471a65938d03365",
      "68d6dc58b7e147c0ac48066ebe72e74e",
      "c7c52a5a4df04002949b8c64d3b6fa9a",
      "1f1595e4e59843beb5270e14c445f454",
      "7715adf4b1b74af2bb7ba792b0570d2d",
      "42e476a5981647a3a27d2a8de2c91809",
      "fe7227607ef84212a046dc3735570b36",
      "687b930d7cab47cc83010be8bb8e58c3",
      "9e853994831146b9b646ab9fff52212d",
      "4d30ab2bb78b4c2a8b60bbc0f18031b4",
      "079269eb96124e8babd3d9eab88f24e4",
      "d29843bd38c84e548856413b2d0edbf2",
      "b22e7941186e4b6399249378b46fb287",
      "2627a648b2d34d10b662af3ae28c6e19",
      "82c96bdbd9914788a55cdc73f983ab34",
      "c38798c268794cf29b19e80485b47b68",
      "2d75a40638cf46c3a64038e69feeda47",
      "28f534e9d2ae45109d822febfe6b7544",
      "177173d0c1334073886772a291c5c5f7",
      "e35e3d5c631548de8e94947f7cd27c8f",
      "b592d8637e554aa7960806a6bd3d7525",
      "19f67a7c077245ad97708a7e0a3ac741",
      "ddfefe22421e4c749dfd5bb72b49fb2e",
      "7e85af86456c485788eafb178eb31d87",
      "dc1caf66cf004c318c92c9ebde8ac39f",
      "96775ff00fa44791b35846a3e781507b",
      "16ef1f7c0f5d41828f9864cb3ff39573",
      "8c9a859815bf4e05888801c93dd3377f",
      "2fffc764fe254711b9c9fbfc572c111a",
      "6a3abe24943b4f0cb0287d218826f773",
      "ef98fecf033844a186a6f51190727dc1",
      "d594dfae93ce4dfaa47f8ca9c53ef1fc",
      "67047ba670f846ce99fe8d8978d8fb94",
      "8d77f41c8f8c4bd4ad06a2ae5f8053cc",
      "6e630ade71764347a8862e0d7cc764d3"
     ]
    },
    "executionInfo": {
     "elapsed": 78657,
     "status": "ok",
     "timestamp": 1764941376487,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "ZzcQTTnZMfEU",
    "outputId": "72dee928-a270-456e-9ea8-9b7fa9652f0d"
   },
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load model (no quantization, no bitsandbytes)\n",
    "torch_dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch_dtype,\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.to(device)\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False  # needed for gradient checkpointing\n",
    "\n",
    "print(\"Model & tokenizer loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2426,
     "status": "ok",
     "timestamp": 1764941378914,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "jr4mZ4b9MhKa",
    "outputId": "d0d31fbb-ec9e-473c-e62a-0c28ffb323e4"
   },
   "outputs": [],
   "source": [
    "lora_cfg = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # Common Qwen target modules\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f36e8ed1662a4866b923cc43a5983732",
      "c106297d7cf7473cbb05732bdb7ad158",
      "3d54071bcdd54fbfb0452e985e3d4748",
      "15808720bf78485bb81de31ff86ce73e",
      "54b5714d74d24e9e9f7141ee13960781",
      "f5e9fe77e88b42d89873841443e8f4da",
      "28ab1f71625948b792405343ba1f5071",
      "a3e4bdb868654ecbac10c0d701205ba8",
      "539b9cb457994848974f5e001ac9288a",
      "857318cb6f7544a8902f43c535c63d53",
      "8092052b32594778bd29ade6876fa4b8",
      "a8a60ad1668b4a78bce478ee223a6b56",
      "b4a6b6c3773240129edcbf1b75c1e4c9",
      "e613ce4d961e4de68f8db8774a69f758",
      "f4f77874be9c4086aab4019d09e82b99",
      "143c34a43fff4681ab45be658149dd5a",
      "040494b75cc34860a0406c39d4021f5b",
      "cf76d1e2e5ce4cc89cb8a8230eae490b",
      "e98ac9a2bdf945f29639ffd0240bd9bd",
      "bff247f4f2ac49349d8823a256105c30",
      "dba29ee62b694704945f0506c043a6d9",
      "9f6369931a1b4a48a87947a94312eeaf"
     ]
    },
    "executionInfo": {
     "elapsed": 16324,
     "status": "ok",
     "timestamp": 1764941395255,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "A4TNMFZYMjf_",
    "outputId": "b50f60a2-e7d5-4f75-dd8d-4c5fe8a28496"
   },
   "outputs": [],
   "source": [
    "max_length = 256  # adjust if you want longer context\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    tokens = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # For causal LM, labels are just input_ids shifted internally\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n",
    "\n",
    "tokenized_train = train_raw.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    ")\n",
    "\n",
    "tokenized_eval = eval_raw.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    ")\n",
    "\n",
    "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_eval.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"Tokenization complete!\")\n",
    "print(tokenized_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1764941414371,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "-wFivahSMkru",
    "outputId": "58e217a0-b547-446d-ce55-d54740fc073c"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 2 if torch.cuda.is_available() else 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"qwen_hinglish_lora\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    warmup_ratio=0.05,\n",
    "    fp16=torch.cuda.is_available(),  # Only use fp16 if GPU available\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "print(\"TrainingArguments loaded successfully!\")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14371379,
     "status": "ok",
     "timestamp": 1764955787060,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "HnNT0SLGMmCF",
    "outputId": "05771c22-6486-40ad-bb21-0453f062549d"
   },
   "outputs": [],
   "source": [
    "print(\"\\nðŸš€ Training started...\\n\")\n",
    "trainer.train()\n",
    "print(\"\\nâœ… Training completed!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58181,
     "status": "ok",
     "timestamp": 1764955845242,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "-Ina7w-CMo7f",
    "outputId": "fc6b33fd-7922-433b-b10f-71e3ceed25f1"
   },
   "outputs": [],
   "source": [
    "save_dir = \"qwen_hinglish_whatsapp_lora\"\n",
    "\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(\"Model & tokenizer saved at:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10250,
     "status": "ok",
     "timestamp": 1764955896435,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "8zffcGgQMq_z",
    "outputId": "9b36fb64-d9f2-4525-8da1-1c206675dec6"
   },
   "outputs": [],
   "source": [
    "def chat(prompt, max_new_tokens=64):\n",
    "    model.eval()\n",
    "    # Simple persona on top of fine-tuned behavior\n",
    "    system_prefix = (\n",
    "        \"You are a flirty, casual Hinglish WhatsApp buddy. \"\n",
    "        \"Reply in 1-2 short sentences, fun and natural.\\n\"\n",
    "    )\n",
    "    full_prompt = system_prefix + f\"<user>: {prompt}\\n<assistant>:\"\n",
    "\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.8,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Cut off the prompt part\n",
    "    gen_ids = output_ids[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    text = tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Quick sanity check\n",
    "tests = [\n",
    "    \"Kya kar rahe ho?\",\n",
    "    \"Kal coffee peene chale?\",\n",
    "    \"Aaj mood thoda off hai...\",\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(\"User :\", t)\n",
    "    print(\"Bot  :\", chat(t))\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 194858,
     "status": "aborted",
     "timestamp": 1764941412198,
     "user": {
      "displayName": "Harsh",
      "userId": "13401630685786581491"
     },
     "user_tz": -330
    },
    "id": "pBBezIaPMsif"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
